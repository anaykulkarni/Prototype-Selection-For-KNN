{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from MnistDataloader import MnistDataloader\n",
    "from oneNNClassifier import oneNNClassifier\n",
    "from utilities import random_sample\n",
    "from os.path  import join\n",
    "import timeit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './dataset/'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "x_train = np.array([np.hstack(x).astype(np.float32) for x in x_train])\n",
    "x_test = np.array([np.hstack(x).astype(np.float32) for x in x_test])\n",
    "y_train = np.array(y_train, np.float32)\n",
    "y_test = np.array(y_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.float32, numpy.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[0][1]), type(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000, 10000, 10000, 784, 5.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test), len(x_train[0]), y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca(X, n_components=50):\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    return X_reduced, pca\n",
    "\n",
    "def facility_location_selection(X_reduced, k):\n",
    "    n_samples = X_reduced.shape[0]\n",
    "    selected_indices = []\n",
    "\n",
    "    # Distances to the nearest selected prototype for each sample\n",
    "    # Initialize to inf since we haven't chosen any prototype yet\n",
    "    min_distances = np.full(n_samples, np.inf)\n",
    "\n",
    "    for _ in range(k):\n",
    "        best_candidate = None\n",
    "        best_improvement = 0.0\n",
    "\n",
    "        # Current coverage cost is the sum of min distances\n",
    "        current_coverage = np.sum(min_distances)\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            # Skip points already selected\n",
    "            if i in selected_indices:\n",
    "                continue\n",
    "\n",
    "            # Compute distances from X[i] to all samples\n",
    "            d = np.linalg.norm(X_reduced - X_reduced[i], axis=1)\n",
    "\n",
    "            # If we were to add i, the new distance for each sample j would be:\n",
    "            #   min( existing distance, distance to X[i] )\n",
    "            new_distances = np.minimum(min_distances, d)\n",
    "\n",
    "            # New coverage cost (sum of these min distances)\n",
    "            new_coverage = np.sum(new_distances)\n",
    "\n",
    "            # Improvement = how much we reduce total distance\n",
    "            improvement = current_coverage - new_coverage\n",
    "            if improvement > best_improvement:\n",
    "                best_improvement = improvement\n",
    "                best_candidate = i\n",
    "\n",
    "        # After checking all samples, pick the point that gives the max improvement\n",
    "        selected_indices.append(best_candidate)\n",
    "\n",
    "        # Update min_distances array with distances to the newly added prototype\n",
    "        d_new_center = np.linalg.norm(X_reduced - X_reduced[best_candidate], axis=1)\n",
    "        min_distances = np.minimum(min_distances, d_new_center)\n",
    "\n",
    "    return selected_indices\n",
    "\n",
    "def select_k_facilities_per_class(X, y, k_per_class=10, n_components=50):\n",
    "\n",
    "    # Reduce dimensionality of the entire dataset\n",
    "    X_reduced, pca_model = perform_pca(X, n_components=n_components)\n",
    "    \n",
    "    unique_classes = np.unique(y)\n",
    "    selected_indices = []\n",
    "\n",
    "    for c in unique_classes:\n",
    "        # Extract the indices for class c\n",
    "        class_indices = np.where(y == c)[0]\n",
    "        X_c_reduced = X_reduced[class_indices]\n",
    "\n",
    "        # Run facility location selection in the reduced space\n",
    "        k_facility_indices = facility_location_selection(X_c_reduced, k_per_class)\n",
    "\n",
    "        # Map back to overall dataset indices\n",
    "        selected_indices_c = class_indices[k_facility_indices]\n",
    "        selected_indices.extend(selected_indices_c)\n",
    "    \n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduction Dimension: 3\n",
      "\tSample size: 100, Accuracy: 0.76, Execution time: 1.8268 seconds\n",
      "\tSample size: 500, Accuracy: 0.86, Execution time: 8.4982 seconds\n",
      "\tSample size: 1000, Accuracy: 0.89, Execution time: 14.3457 seconds\n",
      "\tSample size: 2000, Accuracy: 0.91, Execution time: 28.1585 seconds\n",
      "\tSample size: 5000, Accuracy: 0.94, Execution time: 85.9831 seconds\n",
      "\tSample size: 10000, Accuracy: 0.95, Execution time: 141.7501 seconds\n",
      "Reduction Dimension: 4\n",
      "\tSample size: 100, Accuracy: 0.77, Execution time: 1.4581 seconds\n",
      "\tSample size: 500, Accuracy: 0.87, Execution time: 7.1050 seconds\n",
      "\tSample size: 1000, Accuracy: 0.89, Execution time: 14.3195 seconds\n",
      "\tSample size: 2000, Accuracy: 0.92, Execution time: 28.4070 seconds\n",
      "\tSample size: 5000, Accuracy: 0.94, Execution time: 70.8274 seconds\n",
      "\tSample size: 10000, Accuracy: 0.95, Execution time: 142.5174 seconds\n",
      "Reduction Dimension: 8\n",
      "\tSample size: 100, Accuracy: 0.81, Execution time: 1.4573 seconds\n",
      "\tSample size: 500, Accuracy: 0.89, Execution time: 7.1411 seconds\n",
      "\tSample size: 1000, Accuracy: 0.91, Execution time: 14.2528 seconds\n",
      "\tSample size: 2000, Accuracy: 0.93, Execution time: 28.4301 seconds\n",
      "\tSample size: 5000, Accuracy: 0.94, Execution time: 70.7861 seconds\n",
      "\tSample size: 10000, Accuracy: 0.95, Execution time: 142.7104 seconds\n",
      "Reduction Dimension: 16\n",
      "\tSample size: 100, Accuracy: 0.84, Execution time: 1.4466 seconds\n",
      "\tSample size: 500, Accuracy: 0.91, Execution time: 7.0364 seconds\n",
      "\tSample size: 1000, Accuracy: 0.93, Execution time: 14.1798 seconds\n",
      "\tSample size: 2000, Accuracy: 0.94, Execution time: 28.2110 seconds\n",
      "\tSample size: 5000, Accuracy: 0.95, Execution time: 71.7106 seconds\n",
      "\tSample size: 10000, Accuracy: 0.95, Execution time: 145.5006 seconds\n",
      "Reduction Dimension: 64\n",
      "\tSample size: 100, Accuracy: 0.85, Execution time: 1.4967 seconds\n",
      "\tSample size: 500, Accuracy: 0.92, Execution time: 7.1359 seconds\n",
      "\tSample size: 1000, Accuracy: 0.93, Execution time: 14.2189 seconds\n",
      "\tSample size: 2000, Accuracy: 0.94, Execution time: 28.8018 seconds\n",
      "\tSample size: 5000, Accuracy: 0.95, Execution time: 71.3491 seconds\n",
      "\tSample size: 10000, Accuracy: 0.96, Execution time: 142.1863 seconds\n",
      "Reduction Dimension: 128\n",
      "\tSample size: 100, Accuracy: 0.86, Execution time: 1.4648 seconds\n",
      "\tSample size: 500, Accuracy: 0.92, Execution time: 7.0831 seconds\n",
      "\tSample size: 1000, Accuracy: 0.93, Execution time: 14.2409 seconds\n",
      "\tSample size: 2000, Accuracy: 0.94, Execution time: 28.3035 seconds\n",
      "\tSample size: 5000, Accuracy: 0.95, Execution time: 70.9464 seconds\n",
      "\tSample size: 10000, Accuracy: 0.96, Execution time: 142.1834 seconds\n",
      "Reduction Dimension: 256\n",
      "\tSample size: 100, Accuracy: 0.87, Execution time: 1.4629 seconds\n",
      "\tSample size: 500, Accuracy: 0.92, Execution time: 7.1141 seconds\n",
      "\tSample size: 1000, Accuracy: 0.93, Execution time: 14.2649 seconds\n",
      "\tSample size: 2000, Accuracy: 0.94, Execution time: 28.3843 seconds\n",
      "\tSample size: 5000, Accuracy: 0.95, Execution time: 72.0068 seconds\n",
      "\tSample size: 10000, Accuracy: 0.96, Execution time: 140.4456 seconds\n",
      "Reduction Dimension: 512\n",
      "\tSample size: 100, Accuracy: 0.86, Execution time: 1.4729 seconds\n",
      "\tSample size: 500, Accuracy: 0.92, Execution time: 7.0995 seconds\n",
      "\tSample size: 1000, Accuracy: 0.93, Execution time: 14.1256 seconds\n",
      "\tSample size: 2000, Accuracy: 0.94, Execution time: 28.6554 seconds\n",
      "\tSample size: 5000, Accuracy: 0.95, Execution time: 70.4196 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReduction Dimension:\u001b[39m\u001b[38;5;124m'\u001b[39m, dim)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m M \u001b[38;5;129;01min\u001b[39;00m sample_sizes:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Sample prototypes\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     selected_idxs \u001b[38;5;241m=\u001b[39m select_k_facilities_per_class(x_train, y_train, k_per_class\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(M\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m), n_components\u001b[38;5;241m=\u001b[39mdim)\n\u001b[1;32m     14\u001b[0m     x_sample, y_sample \u001b[38;5;241m=\u001b[39m x_train[selected_idxs], y_train[selected_idxs]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Model\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m, in \u001b[0;36mselect_k_facilities_per_class\u001b[0;34m(X, y, k_per_class, n_components)\u001b[0m\n\u001b[1;32m     62\u001b[0m X_c_reduced \u001b[38;5;241m=\u001b[39m X_reduced[class_indices]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Run facility location selection in the reduced space\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m k_facility_indices \u001b[38;5;241m=\u001b[39m facility_location_selection(X_c_reduced, k_per_class)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Map back to overall dataset indices\u001b[39;00m\n\u001b[1;32m     68\u001b[0m selected_indices_c \u001b[38;5;241m=\u001b[39m class_indices[k_facility_indices]\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mfacility_location_selection\u001b[0;34m(X_reduced, k)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Compute distances from X[i] to all samples\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(X_reduced \u001b[38;5;241m-\u001b[39m X_reduced[i], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# If we were to add i, the new distance for each sample j would be:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#   min( existing distance, distance to X[i] )\u001b[39;00m\n\u001b[1;32m     31\u001b[0m new_distances \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(min_distances, d)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/linalg/linalg.py:2583\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2581\u001b[0m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m     s \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mconj() \u001b[38;5;241m*\u001b[39m x)\u001b[38;5;241m.\u001b[39mreal\n\u001b[0;32m-> 2583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(add\u001b[38;5;241m.\u001b[39mreduce(s, axis\u001b[38;5;241m=\u001b[39maxis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims))\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[1;32m   2585\u001b[0m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mord\u001b[39m, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train set is sampled using M/10 prototypes per class\n",
    "\n",
    "# sample_sizes = [10, 20, 30, 40, 50]\n",
    "reduced_dims = [3, 4, 8, 16, 64, 128, 256, 512, 784]\n",
    "sample_sizes = [100, 500, 1000, 2000, 5000, 10000]\n",
    "storage = {} \n",
    "execution_data = {d:[] for d in reduced_dims}\n",
    "\n",
    "for dim in reduced_dims:\n",
    "    print('Reduction Dimension:', dim)\n",
    "    for M in sample_sizes:\n",
    "        # Sample prototypes\n",
    "        selected_idxs = select_k_facilities_per_class(x_train, y_train, k_per_class= int(M/10), n_components=dim)\n",
    "        x_sample, y_sample = x_train[selected_idxs], y_train[selected_idxs]\n",
    "\n",
    "        # Model\n",
    "        model = oneNNClassifier(x_sample, y_sample)\n",
    "        \n",
    "        # Timing\n",
    "        elapsed_time = timeit.timeit(lambda: model.predict(x_test, size=M, storage=storage, weighted=False), \n",
    "                                number=1)\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(y_test, storage[M])\n",
    "\n",
    "        print(f\"\\tSample size: {M}, Accuracy: {accuracy:.2f}, Execution time: {elapsed_time:.4f} seconds\")\n",
    "        # Store Data\n",
    "        execution_data[dim].append({\"sample_size\": M, \"time\": elapsed_time, \"accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"execution_data_facility_location.json\", \"w\") as file:\n",
    "    json.dump(execution_data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
